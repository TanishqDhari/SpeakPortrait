{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Note:\n",
        "The following steps include:\n",
        "- Setup Environment  \n",
        "    - ***If there is a numpy 2.x dependency issue, you can ignore it.***\n",
        "- Restart Colab Runtime  \n",
        "    - ***Important!***\n",
        "- Prepare Code and Models  \n",
        "- Inference and Display  "
      ],
      "metadata": {
        "id": "UXEDUgKdZETY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment"
      ],
      "metadata": {
        "id": "vjynPPFCYYMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### show gpu info"
      ],
      "metadata": {
        "id": "8K-2slSUULj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "KgCi6NxGUTr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check torch"
      ],
      "metadata": {
        "id": "JFwShY0SSpKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "JhdOnbTNSnj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install packages"
      ],
      "metadata": {
        "id": "8Ux56aUnSyzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# about 0.5~1min\n",
        "!pip install tensorrt==8.6.1 librosa tqdm filetype imageio opencv_python_headless scikit-image cython cuda-python imageio-ffmpeg colored polygraphy numpy==2.0.1"
      ],
      "metadata": {
        "id": "auE5eVqCSnBx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# about 10s\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fEQpNZHAN92P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# about 10s\n",
        "!apt update\n",
        "!apt install ffmpeg -y"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6iPwAD8aOAUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# about 1min\n",
        "# If it doesn't work, you may need to add this command:\n",
        "!apt install -y libcudnn8"
      ],
      "metadata": {
        "id": "r8IofnIB4Tgj",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### restart runtime"
      ],
      "metadata": {
        "id": "c-hcMYRsTexu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !!!\n",
        "# You need to restart the runtime to ensure that the newly installed environment takes effect\n",
        "# !!!\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "CnU-NrlsS8LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/drive/MyDrive/colab/gen\n",
        "!ls"
      ],
      "metadata": {
        "id": "EEVhFj4YDRqv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check environment"
      ],
      "metadata": {
        "id": "gBTPG7bRT0sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tensorrt as trt\n",
        "print(np.__version__)\n",
        "print(torch.__version__)\n",
        "print(trt.__version__)"
      ],
      "metadata": {
        "id": "BX9cqefNTzy1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Code and Models"
      ],
      "metadata": {
        "id": "uavpfUqbYqdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare code"
      ],
      "metadata": {
        "id": "aDkcDaetUZyr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfs0_VEyJm4u",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"ditto-talkinghead\"):\n",
        "    !git clone https://github.com/antgroup/ditto-talkinghead.git\n",
        "else:\n",
        "    print(\"ditto-talkinghead already cloned.\")\n",
        "\n",
        "%cd ditto-talkinghead\n",
        "!git pull\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare model"
      ],
      "metadata": {
        "id": "6DA4nImZUfPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# about 1~2min\n",
        "!git lfs install\n",
        "if not os.path.isdir(\"checkpoints\"):\n",
        "    !git clone https://huggingface.co/digital-avatar/ditto-talkinghead checkpoints\n",
        "\n",
        "%cd checkpoints\n",
        "!git pull\n",
        "!ls\n",
        "\n",
        "%cd ..\n",
        "!ls"
      ],
      "metadata": {
        "id": "Gf54LtAfQ890",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### check GPU architecture"
      ],
      "metadata": {
        "id": "FTuJfoveUmsF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OB8Hcg6xXyZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# about 1~2min\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def cvt_custom_trt():\n",
        "    from scripts.cvt_onnx_to_trt import main as cvt_trt\n",
        "    onnx_dir = \"./checkpoints/ditto_onnx\"\n",
        "    trt_dir = \"./checkpoints/ditto_trt_custom\"\n",
        "    assert os.path.isdir(onnx_dir)\n",
        "    os.makedirs(trt_dir, exist_ok=True)\n",
        "    grid_sample_plugin_file = os.path.join(onnx_dir, \"libgrid_sample_3d_plugin.so\")\n",
        "    cvt_trt(onnx_dir, trt_dir, grid_sample_plugin_file)\n",
        "    return trt_dir\n",
        "\n",
        "\n",
        "def download_Non_Ampere_trt():\n",
        "    !pip install --upgrade --no-cache-dir gdown\n",
        "    !gdown https://drive.google.com/drive/folders/1-1qnqy0D9ICgRh8iNY_22j9ieNRC0-zf?usp=sharing -O ./checkpoints/ditto_trt --folder\n",
        "    trt_dir = \"./checkpoints/ditto_trt\"\n",
        "    return trt_dir\n",
        "\n",
        "\n",
        "if torch.cuda.get_device_capability()[0] < 8:\n",
        "    # data_root = cvt_custom_trt()    # cvt\n",
        "    # The conversion is slow, so you can download pre-converted files.\n",
        "    data_root = download_Non_Ampere_trt()\n",
        "else:\n",
        "    data_root = \"./checkpoints/ditto_trt_Ampere_Plus\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "wFNuRUa3Y1gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run inference"
      ],
      "metadata": {
        "id": "VZyDsSITWhtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init, about 10s\n",
        "from inference import StreamSDK, run\n",
        "# data_root = \"./checkpoints/ditto_trt_custom\"   # model dir\n",
        "cfg_pkl = \"./checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl\"     # cfg pkl\n",
        "print(data_root)\n",
        "print(cfg_pkl)\n",
        "SDK = StreamSDK(cfg_pkl, data_root)"
      ],
      "metadata": {
        "id": "e2XiC3zjWv54",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### display result"
      ],
      "metadata": {
        "id": "MSnGPdztwUHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "ngrok.set_auth_token('2zBytGMcVk9x9BMsHaTl8LHQCsk_4ruiCTWtjRUNjapivYdEd')\n",
        "app = Flask(__name__)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸ”— Public URL: {public_url}\")\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    image = request.files.get('image')\n",
        "    audio = request.files.get('audio')\n",
        "\n",
        "    if not image or not audio:\n",
        "        return \"Missing image or audio\", 400\n",
        "\n",
        "    image_path = \"/content/image.png\"\n",
        "    audio_path = \"/content/audio.wav\"\n",
        "    output_path = \"/content/result.mp4\"\n",
        "\n",
        "    image.save(image_path)\n",
        "    audio.save(audio_path)\n",
        "\n",
        "    try:\n",
        "        run(SDK, audio_path, image_path, output_path)\n",
        "    except Exception as e:\n",
        "        return f\"Inference failed: {e}\", 500\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "        return \"Video not found\", 500\n",
        "\n",
        "    return send_file(output_path, mimetype=\"video/mp4\", as_attachment=True)\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "id": "XZXsZ-yxOPhz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, send_file\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# NGROK SETUP\n",
        "ngrok.set_auth_token('2zBytGMcVk9x9BMsHaTl8LHQCsk_4ruiCTWtjRUNjapivYdEd')\n",
        "app = Flask(__name__)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸ”— Public URL: {public_url}\")\n",
        "\n",
        "def get_seq_len_from_audio(audio_path, fps=25, target_sr=16000):\n",
        "    audio, sr = librosa.load(audio_path, sr=target_sr)\n",
        "    duration_sec = len(audio) / sr\n",
        "    seq_len = int(duration_sec * fps)\n",
        "    return seq_len\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    image = request.files.get('image')\n",
        "    audio = request.files.get('audio')\n",
        "    emotion_index = request.form.get('emotion')\n",
        "\n",
        "    if not image or not audio or emotion_index is None:\n",
        "        return \"Missing image, audio, or emotion\", 400\n",
        "\n",
        "    try:\n",
        "        emotion_index = int(emotion_index)\n",
        "        if not (0 <= emotion_index <= 7):\n",
        "            return \"Emotion index must be between 0 and 7\", 400\n",
        "    except ValueError:\n",
        "        return \"Emotion index must be an integer\", 400\n",
        "\n",
        "    image_path = \"/content/image.png\"\n",
        "    audio_path = \"/content/audio.wav\"\n",
        "    output_path = \"/content/result.mp4\"\n",
        "    image.save(image_path)\n",
        "    audio.save(audio_path)\n",
        "\n",
        "    try:\n",
        "        # 1. Get seq_len\n",
        "        seq_len = get_seq_len_from_audio(audio_path)\n",
        "\n",
        "        # 2. Create emotion array\n",
        "        emo_arr = np.zeros((seq_len, 8), dtype=np.float32)\n",
        "        emo_arr[:, emotion_index] = 1.0\n",
        "\n",
        "        # 3. Prepare kwargs\n",
        "        setup_kwargs = {\"emo\": emo_arr}\n",
        "        more_kwargs = {\n",
        "            \"setup_kwargs\": setup_kwargs,\n",
        "            \"run_kwargs\": {}\n",
        "        }\n",
        "\n",
        "        # 4. Run model\n",
        "        SDK = StreamSDK(cfg_pkl, data_root)\n",
        "        run(SDK, audio_path, image_path, output_path, more_kwargs=more_kwargs)\n",
        "        del SDK\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Inference failed: {e}\", 500\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "        return \"Video not found\", 500\n",
        "\n",
        "    return send_file(output_path, mimetype=\"video/mp4\", as_attachment=True)\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bC6xldGYZXHI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}